{"cells":[{"cell_type":"markdown","metadata":{"id":"RkArmY71DTqs"},"source":["# **Counting Algorithms**"]},{"cell_type":"markdown","source":["## **Import Libraries**"],"metadata":{"id":"NYoF16d8hZYq"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"7s5w4e8igLvA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719091340531,"user_tz":-480,"elapsed":11841,"user":{"displayName":"Muhammad Ariff Ridzlan Mohd Faudzi","userId":"14562904493941638965"}},"outputId":"1508f67a-b083-4549-96dd-06886eba50f9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n"]}],"source":["import os\n","import shutil\n","import random\n","\n","!pip install tqdm --upgrade\n","from tqdm.notebook import tqdm"]},{"cell_type":"markdown","metadata":{"id":"RXyZLUhpDTqz"},"source":["## **Install Ultralytics**"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"grULmxelVhf5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719091413729,"user_tz":-480,"elapsed":73219,"user":{"displayName":"Muhammad Ariff Ridzlan Mohd Faudzi","userId":"14562904493941638965"}},"outputId":"b3223238-a480-47ea-ee20-c36d7f0826cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.2.39-py3-none-any.whl (792 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/792.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.4/792.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m788.5/792.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m792.7/792.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.25.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.3.0+cu121)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.18.0+cu121)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.4)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.0-py3-none-any.whl (25 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.15.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n","Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n","Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n","Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n","Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n","Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n","Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n","Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n","Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n","Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n","  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n","Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.3.0)\n","Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n","Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n","Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 ultralytics-8.2.39 ultralytics-thop-2.0.0\n"]}],"source":["!pip install ultralytics"]},{"cell_type":"markdown","metadata":{"id":"N5fTYaCPDTq4"},"source":["## **Connect to Google Drive**"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"C24nycBsg037","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719091440358,"user_tz":-480,"elapsed":26669,"user":{"displayName":"Muhammad Ariff Ridzlan Mohd Faudzi","userId":"14562904493941638965"}},"outputId":"00855f30-616e-4559-cfa4-1c6cb5f844ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["## **Prepare Folder Path YOLOv8 Data**"],"metadata":{"id":"KvbN5a6jhh5d"}},{"cell_type":"code","execution_count":4,"metadata":{"id":"HOTmdh2Mg1j6","executionInfo":{"status":"ok","timestamp":1719091440358,"user_tz":-480,"elapsed":15,"user":{"displayName":"Muhammad Ariff Ridzlan Mohd Faudzi","userId":"14562904493941638965"}}},"outputs":[],"source":["train_path_img = \"./yolo_data/images/train/\"\n","train_path_label = \"./yolo_data/labels/train/\"\n","val_path_img = \"./yolo_data/images/val/\"\n","val_path_label = \"./yolo_data/labels/val/\"\n","test_path = \"./yolo_data/test\""]},{"cell_type":"markdown","metadata":{"id":"SRXQH_20gqeO"},"source":["## **Creating the Training and Test Set**"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"ADx6NEpng6jo","colab":{"base_uri":"https://localhost:8080/","height":168,"referenced_widgets":["b4cf3390a1c845eda58bf6c02b382ca1","2734588b65e84dd4904f3d5563a6e2ba","eb70def88cd8487e8ce2b293165933b6","f72f93c0614c4772a4f8aa908d8dd946","f2a7e4a5abba40f7aab71745f828985b","5de1370baf694350af0d39137fbeff68","9caf1ff5c3254c5fb535e04fe2aa556b","4a3e727260f2477189e94d6ca03e98bd","4a26e413d9d843f081b472be2a9b371e","ffa49667722249ea8dddd3a7fb895afa","4e9bbc64fa564b22a0cb356bdb8a68f9","619c52c7f79240b88eabb6f589d2d46e","41a9367189064992946279c16197585e","382b3f4df7fd4ad7b121c80bbb4cc99d","8190a7de4893415bb65b6c535fd44bd8","052d8d37b4e7460394f4635aad0d5c59","3de18ce4302d4a638f0fbd917443a4ba","15ad1f71033a48ea8bd13fe1a2e21972","45340c2acec74c0594c521e7f85f9058","2475354551b94056aa4d93d37c3d98eb","dc560f83e2da4f30b2078fbd3a2c3420","021daa632d4f4e4e9c53254150c8caa5"]},"executionInfo":{"status":"ok","timestamp":1719091468932,"user_tz":-480,"elapsed":28586,"user":{"displayName":"Muhammad Ariff Ridzlan Mohd Faudzi","userId":"14562904493941638965"}},"outputId":"f05a66e6-02ff-4913-df5b-482e0c834df9"},"outputs":[{"output_type":"stream","name":"stdout","text":["------ PROCESS STARTED -------\n","--- This folder has a total number of 220 images---\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/176 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b4cf3390a1c845eda58bf6c02b382ca1"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------ Training data created with 80% split 176 images -------\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/44 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"619c52c7f79240b88eabb6f589d2d46e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["------ Testing data created with a total of 44 images ----------\n","------ TASK COMPLETED -------\n"]}],"source":["'''\n","Split the dataset into train and test and creates the train.txt and test.txt with\n","the respective path of the images in each folder\n","'''\n","\n","def train_test_split(path,neg_path=None, split = 0.2):\n","    print(\"------ PROCESS STARTED -------\")\n","\n","    files = list(set([name[:-4] for name in os.listdir(path)]))\n","\n","    print (f\"--- This folder has a total number of {len(files)} images---\")\n","    random.seed(42)\n","    random.shuffle(files)\n","\n","    test_size = int(len(files) * split)\n","    train_size = len(files) - test_size\n","\n","    os.makedirs(train_path_img, exist_ok = True)\n","    os.makedirs(train_path_label, exist_ok = True)\n","    os.makedirs(val_path_img, exist_ok = True)\n","    os.makedirs(val_path_label, exist_ok = True)\n","\n","    for filex in tqdm(files[:train_size]):\n","      if filex == 'classes':\n","          continue\n","      shutil.copy2(path + filex + '.jpg',f\"{train_path_img}/\" + filex + '.jpg' )\n","      shutil.copy2(path + filex + '.txt', f\"{train_path_label}/\" + filex + '.txt')\n","\n","    print(f\"------ Training data created with 80% split {len(files[:train_size])} images -------\")\n","\n","    if neg_path:\n","        neg_images = list(set([name[:-4] for name in os.listdir(neg_path)]))\n","        for filex in tqdm(neg_images):\n","            shutil.copy2(neg_path+filex+ \".jpg\", f\"{train_path_img}/\" + filex + '.jpg')\n","\n","        print(f\"------ Total  {len(neg_images)} negative images added to the training data -------\")\n","\n","        print(f\"------ TOTAL Training data created with {len(files[:train_size]) + len(neg_images)} images -------\")\n","\n","    for filex in tqdm(files[train_size:]):\n","      if filex == 'classes':\n","          continue\n","      shutil.copy2(path + filex + '.jpg', f\"{val_path_img}/\" + filex + '.jpg' )\n","      shutil.copy2(path + filex + '.txt', f\"{val_path_label}/\" + filex + '.txt')\n","\n","    print(f\"------ Testing data created with a total of {len(files[train_size:])} images ----------\")\n","    print(\"------ TASK COMPLETED -------\")\n","\n","train_test_split('/content/drive/MyDrive/yolov8/data/')"]},{"cell_type":"markdown","source":["## **Check Ultralytics**"],"metadata":{"id":"eAf86C67hwrz"}},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"udzAp2TzhSwZ","outputId":"ca0941b9-4952-4fd8-d2b3-cd98d025de31","executionInfo":{"status":"ok","timestamp":1719091472849,"user_tz":-480,"elapsed":3924,"user":{"displayName":"Muhammad Ariff Ridzlan Mohd Faudzi","userId":"14562904493941638965"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.39 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Setup complete ✅ (2 CPUs, 12.7 GB RAM, 31.7/78.2 GB disk)\n"]}],"source":["import ultralytics\n","ultralytics.checks()"]},{"cell_type":"markdown","metadata":{"id":"n5bwE3zckX3i"},"source":["## **Training the YOLOv8**"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"p4Eng64Fj1SJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719092829372,"user_tz":-480,"elapsed":341167,"user":{"displayName":"Muhammad Ariff Ridzlan Mohd Faudzi","userId":"14562904493941638965"}},"outputId":"2000448d-1753-4cec-c69e-739cf3021d2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8s.pt to 'yolov8s.pt'...\n","100% 21.5M/21.5M [00:00<00:00, 414MB/s]\n","Ultralytics YOLOv8.2.39 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8s.pt, data=/content/drive/MyDrive/yolov8/dataset.yaml, epochs=24, time=None, patience=100, batch=8, imgsz=1600, save=True, save_period=-1, cache=False, device=None, workers=8, project=/content/drive/MyDrive/yolov8/training_results, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=/content/drive/MyDrive/yolov8/training_results/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 108MB/s]\n","Overriding model.yaml nc=80 with nc=4\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n","  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n","  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n","  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n"," 22        [15, 18, 21]  1   2117596  ultralytics.nn.modules.head.Detect           [4, [128, 256, 512]]          \n","Model summary: 225 layers, 11137148 parameters, 11137132 gradients, 28.7 GFLOPs\n","\n","Transferred 349/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir /content/drive/MyDrive/yolov8/training_results/train', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n","100% 6.23M/6.23M [00:00<00:00, 363MB/s]\n","/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n","  return F.conv2d(input, weight, bias, self.stride,\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/yolo_data/labels/train... 176 images, 0 backgrounds, 0 corrupt: 100% 176/176 [00:00<00:00, 1399.30it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/yolo_data/labels/train.cache\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/yolo_data/labels/val... 44 images, 0 backgrounds, 0 corrupt: 100% 44/44 [00:00<00:00, 787.30it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/yolo_data/labels/val.cache\n","Plotting labels to /content/drive/MyDrive/yolov8/training_results/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 1600 train, 1600 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/yolov8/training_results/train\u001b[0m\n","Starting training for 24 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/24      12.5G      1.808      13.57      2.478         19       1600: 100% 22/22 [00:51<00:00,  2.34s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0% 0/3 [00:00<?, ?it/s]WARNING ⚠️ NMS time limit 2.800s exceeded\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  33% 1/3 [00:06<00:12,  6.42s/it]WARNING ⚠️ NMS time limit 2.800s exceeded\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):  67% 2/3 [00:09<00:04,  4.67s/it]WARNING ⚠️ NMS time limit 2.600s exceeded\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:13<00:00,  4.56s/it]\n","                   all         44         44      0.694      0.241      0.271      0.171\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/24      12.4G     0.8023       3.65      1.479         19       1600: 100% 22/22 [00:41<00:00,  1.87s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.01it/s]\n","                   all         44         44       0.34      0.491      0.277      0.181\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/24      12.4G     0.9339      2.763      1.657         15       1600: 100% 22/22 [00:47<00:00,  2.16s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.55it/s]\n","                   all         44         44      0.326      0.647      0.426      0.231\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/24      12.4G     0.9257      2.025      1.598         20       1600: 100% 22/22 [00:47<00:00,  2.16s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.08it/s]\n","                   all         44         44      0.705      0.416      0.465      0.257\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/24      12.4G     0.9003      1.955      1.525         20       1600: 100% 22/22 [00:47<00:00,  2.16s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.51it/s]\n","                   all         44         44      0.594       0.26       0.44      0.259\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/24      12.4G      1.002      1.665      1.619         17       1600: 100% 22/22 [00:45<00:00,  2.07s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.54it/s]\n","                   all         44         44      0.653      0.571       0.62      0.411\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/24      12.4G     0.9584       1.47      1.528         20       1600: 100% 22/22 [00:47<00:00,  2.16s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.79it/s]\n","                   all         44         44      0.589      0.687       0.72      0.507\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/24      12.4G     0.7921      1.402      1.444         27       1600: 100% 22/22 [00:48<00:00,  2.19s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.09it/s]\n","                   all         44         44      0.498       0.69      0.652      0.496\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/24      12.4G     0.8073      1.192      1.361         13       1600: 100% 22/22 [00:45<00:00,  2.07s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.84it/s]\n","                   all         44         44      0.664      0.703      0.761      0.564\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/24      12.4G     0.7653      1.129      1.387         21       1600: 100% 22/22 [00:46<00:00,  2.09s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.38it/s]\n","                   all         44         44      0.761        0.6      0.707      0.531\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/24      12.4G     0.7342       1.09      1.355         20       1600: 100% 22/22 [00:51<00:00,  2.35s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.17it/s]\n","                   all         44         44      0.679      0.812      0.821      0.669\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/24      12.4G     0.7711      1.007      1.378         15       1600: 100% 22/22 [00:47<00:00,  2.15s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.56it/s]\n","                   all         44         44      0.749       0.68      0.698      0.563\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/24      12.4G      0.747     0.9517       1.34         20       1600: 100% 22/22 [00:44<00:00,  2.04s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.17it/s]\n","                   all         44         44      0.826      0.847      0.927       0.77\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/24      12.4G     0.7104     0.9581      1.329         19       1600: 100% 22/22 [00:49<00:00,  2.26s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.19it/s]\n","                   all         44         44      0.771      0.914      0.933      0.804\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n","  self.pid = os.fork()\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/24      12.4G     0.7731      1.099      1.348          8       1600: 100% 22/22 [00:53<00:00,  2.42s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.12it/s]\n","                   all         44         44      0.793      0.845      0.886      0.747\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/24      12.4G     0.7174      1.022      1.266          8       1600: 100% 22/22 [00:45<00:00,  2.07s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.77it/s]\n","                   all         44         44      0.863      0.796      0.873      0.736\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/24      12.4G     0.7633     0.9363      1.314          8       1600: 100% 22/22 [00:42<00:00,  1.94s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.12it/s]\n","                   all         44         44      0.908      0.785        0.9      0.762\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/24      12.4G     0.6635      0.941       1.25          8       1600: 100% 22/22 [00:45<00:00,  2.07s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.81it/s]\n","                   all         44         44      0.863      0.839      0.892      0.771\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/24      12.4G     0.7025     0.8521      1.203          8       1600: 100% 22/22 [00:42<00:00,  1.94s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.30it/s]\n","                   all         44         44      0.888       0.85      0.897      0.761\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/24      12.4G     0.6696      0.807       1.25          8       1600: 100% 22/22 [00:44<00:00,  2.00s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.80it/s]\n","                   all         44         44       0.83      0.958      0.904      0.771\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      21/24      12.4G     0.6208     0.7933      1.196          8       1600: 100% 22/22 [00:45<00:00,  2.08s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.29it/s]\n","                   all         44         44      0.892      0.919      0.912      0.784\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      22/24      12.4G      0.606     0.8606      1.202          8       1600: 100% 22/22 [00:43<00:00,  1.99s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:02<00:00,  1.41it/s]\n","                   all         44         44      0.873      0.873      0.917      0.788\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      23/24      12.4G     0.6428       0.73      1.164          8       1600: 100% 22/22 [00:45<00:00,  2.05s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  2.21it/s]\n","                   all         44         44      0.952      0.864      0.944      0.809\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      24/24      12.4G     0.5607     0.6582      1.169          8       1600: 100% 22/22 [00:42<00:00,  1.94s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:01<00:00,  1.72it/s]\n","                   all         44         44      0.935      0.888       0.95       0.84\n","\n","24 epochs completed in 0.356 hours.\n","Optimizer stripped from /content/drive/MyDrive/yolov8/training_results/train/weights/last.pt, 22.7MB\n","Optimizer stripped from /content/drive/MyDrive/yolov8/training_results/train/weights/best.pt, 22.7MB\n","\n","Validating /content/drive/MyDrive/yolov8/training_results/train/weights/best.pt...\n","Ultralytics YOLOv8.2.39 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11127132 parameters, 0 gradients, 28.4 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 3/3 [00:07<00:00,  2.50s/it]\n","                   all         44         44      0.936      0.888       0.95      0.839\n","              Object 1         10         10          1      0.791      0.876      0.824\n","              Object 2         13         13      0.926      0.963      0.968      0.848\n","              Object 3         11         11       0.97          1      0.995      0.838\n","              Object 4         10         10      0.847        0.8      0.962      0.846\n","Speed: 1.1ms preprocess, 19.8ms inference, 0.0ms loss, 3.1ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/yolov8/training_results/train\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}],"source":["!yolo task=detect mode=train model=yolov8s.pt data=/content/drive/MyDrive/yolov8/dataset.yaml epochs=24 imgsz=1600 batch=8 project=/content/drive/MyDrive/yolov8/training_results"]},{"cell_type":"markdown","metadata":{"id":"xRq4HW-Nopo9"},"source":["## **Testing the YOLOv8**"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"0YYuevqfnyak","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1719092879908,"user_tz":-480,"elapsed":50539,"user":{"displayName":"Muhammad Ariff Ridzlan Mohd Faudzi","userId":"14562904493941638965"}},"outputId":"83d12292-eb76-4a58-eb78-1ae12685e682"},"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics YOLOv8.2.39 🚀 Python-3.10.12 torch-2.3.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n","Model summary (fused): 168 layers, 11127132 parameters, 0 gradients, 28.4 GFLOPs\n","\n","image 1/24 /content/drive/MyDrive/yolov8/test_images/IMG_1030.jpg: 1088x1600 2 Object 1s, 1 Object 3, 1 Object 4, 70.0ms\n","image 2/24 /content/drive/MyDrive/yolov8/test_images/IMG_1031.jpg: 1088x1600 1 Object 1, 1 Object 3, 1 Object 4, 54.5ms\n","image 3/24 /content/drive/MyDrive/yolov8/test_images/IMG_3188.jpg: 1088x1600 2 Object 1s, 2 Object 3s, 54.7ms\n","image 4/24 /content/drive/MyDrive/yolov8/test_images/IMG_3189.jpg: 1088x1600 2 Object 1s, 2 Object 3s, 2 Object 4s, 54.6ms\n","image 5/24 /content/drive/MyDrive/yolov8/test_images/IMG_3190.jpg: 1088x1600 2 Object 1s, 1 Object 3, 54.6ms\n","image 6/24 /content/drive/MyDrive/yolov8/test_images/IMG_3191.jpg: 1088x1600 2 Object 1s, 1 Object 3, 54.5ms\n","image 7/24 /content/drive/MyDrive/yolov8/test_images/IMG_3192.jpg: 1088x1600 2 Object 1s, 1 Object 4, 54.6ms\n","image 8/24 /content/drive/MyDrive/yolov8/test_images/IMG_3193.jpg: 1088x1600 1 Object 1, 1 Object 3, 54.6ms\n","image 9/24 /content/drive/MyDrive/yolov8/test_images/IMG_3194.jpg: 1088x1600 1 Object 2, 1 Object 3, 54.6ms\n","image 10/24 /content/drive/MyDrive/yolov8/test_images/IMG_3195.jpg: 1088x1600 2 Object 3s, 2 Object 4s, 54.6ms\n","image 11/24 /content/drive/MyDrive/yolov8/test_images/IMG_3196.jpg: 1088x1600 1 Object 3, 1 Object 4, 54.5ms\n","image 12/24 /content/drive/MyDrive/yolov8/test_images/IMG_3197.jpg: 1088x1600 1 Object 1, 1 Object 3, 54.5ms\n","image 13/24 /content/drive/MyDrive/yolov8/test_images/IMG_3198.jpg: 1088x1600 1 Object 1, 1 Object 3, 1 Object 4, 54.5ms\n","image 14/24 /content/drive/MyDrive/yolov8/test_images/IMG_3199.jpg: 1088x1600 1 Object 1, 3 Object 3s, 2 Object 4s, 54.6ms\n","image 15/24 /content/drive/MyDrive/yolov8/test_images/IMG_3200.jpg: 1088x1600 1 Object 1, 2 Object 3s, 1 Object 4, 54.6ms\n","image 16/24 /content/drive/MyDrive/yolov8/test_images/IMG_3201.jpg: 1088x1600 2 Object 1s, 1 Object 2, 1 Object 3, 1 Object 4, 54.6ms\n","image 17/24 /content/drive/MyDrive/yolov8/test_images/IMG_3202.jpg: 1088x1600 1 Object 2, 1 Object 3, 54.6ms\n","image 18/24 /content/drive/MyDrive/yolov8/test_images/IMG_3203.jpg: 1088x1600 2 Object 3s, 1 Object 4, 54.6ms\n","image 19/24 /content/drive/MyDrive/yolov8/test_images/IMG_3204.jpg: 1088x1600 1 Object 3, 54.6ms\n","image 20/24 /content/drive/MyDrive/yolov8/test_images/IMG_3205.jpg: 1088x1600 1 Object 1, 1 Object 3, 1 Object 4, 54.6ms\n","image 21/24 /content/drive/MyDrive/yolov8/test_images/IMG_3206.jpg: 1088x1600 3 Object 2s, 1 Object 3, 2 Object 4s, 54.6ms\n","image 22/24 /content/drive/MyDrive/yolov8/test_images/IMG_3207.jpg: 1088x1600 1 Object 1, 2 Object 3s, 1 Object 4, 54.6ms\n","image 23/24 /content/drive/MyDrive/yolov8/test_images/IMG_3208.jpg: 1088x1600 2 Object 3s, 54.6ms\n","image 24/24 /content/drive/MyDrive/yolov8/test_images/IMG_3209.jpg: 1088x1600 1 Object 1, 1 Object 3, 54.6ms\n","Speed: 14.6ms preprocess, 55.2ms inference, 24.9ms postprocess per image at shape (1, 3, 1088, 1600)\n","Results saved to \u001b[1mruns/detect/predict\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}],"source":["!yolo task=detect mode=predict model=/content/drive/MyDrive/yolov8/training_results/train/weights/best.pt conf=0.25 source=/content/drive/MyDrive/yolov8/test_images"]},{"cell_type":"markdown","metadata":{"id":"2C3YxUGeDTrS"},"source":["## **Copy the Prediction to GDrive**"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"yozuGgMMBBWy","executionInfo":{"status":"ok","timestamp":1719092880486,"user_tz":-480,"elapsed":580,"user":{"displayName":"Muhammad Ariff Ridzlan Mohd Faudzi","userId":"14562904493941638965"}}},"outputs":[],"source":["!cp -r /content/runs/detect/predict /content/drive/MyDrive/yolov8/output"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b4cf3390a1c845eda58bf6c02b382ca1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2734588b65e84dd4904f3d5563a6e2ba","IPY_MODEL_eb70def88cd8487e8ce2b293165933b6","IPY_MODEL_f72f93c0614c4772a4f8aa908d8dd946"],"layout":"IPY_MODEL_f2a7e4a5abba40f7aab71745f828985b"}},"2734588b65e84dd4904f3d5563a6e2ba":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5de1370baf694350af0d39137fbeff68","placeholder":"​","style":"IPY_MODEL_9caf1ff5c3254c5fb535e04fe2aa556b","value":"100%"}},"eb70def88cd8487e8ce2b293165933b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a3e727260f2477189e94d6ca03e98bd","max":176,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4a26e413d9d843f081b472be2a9b371e","value":176}},"f72f93c0614c4772a4f8aa908d8dd946":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ffa49667722249ea8dddd3a7fb895afa","placeholder":"​","style":"IPY_MODEL_4e9bbc64fa564b22a0cb356bdb8a68f9","value":" 176/176 [00:24&lt;00:00, 28.90it/s]"}},"f2a7e4a5abba40f7aab71745f828985b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5de1370baf694350af0d39137fbeff68":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9caf1ff5c3254c5fb535e04fe2aa556b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a3e727260f2477189e94d6ca03e98bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a26e413d9d843f081b472be2a9b371e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ffa49667722249ea8dddd3a7fb895afa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e9bbc64fa564b22a0cb356bdb8a68f9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"619c52c7f79240b88eabb6f589d2d46e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_41a9367189064992946279c16197585e","IPY_MODEL_382b3f4df7fd4ad7b121c80bbb4cc99d","IPY_MODEL_8190a7de4893415bb65b6c535fd44bd8"],"layout":"IPY_MODEL_052d8d37b4e7460394f4635aad0d5c59"}},"41a9367189064992946279c16197585e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3de18ce4302d4a638f0fbd917443a4ba","placeholder":"​","style":"IPY_MODEL_15ad1f71033a48ea8bd13fe1a2e21972","value":"100%"}},"382b3f4df7fd4ad7b121c80bbb4cc99d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_45340c2acec74c0594c521e7f85f9058","max":44,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2475354551b94056aa4d93d37c3d98eb","value":44}},"8190a7de4893415bb65b6c535fd44bd8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dc560f83e2da4f30b2078fbd3a2c3420","placeholder":"​","style":"IPY_MODEL_021daa632d4f4e4e9c53254150c8caa5","value":" 44/44 [00:01&lt;00:00, 28.48it/s]"}},"052d8d37b4e7460394f4635aad0d5c59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3de18ce4302d4a638f0fbd917443a4ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15ad1f71033a48ea8bd13fe1a2e21972":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45340c2acec74c0594c521e7f85f9058":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2475354551b94056aa4d93d37c3d98eb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dc560f83e2da4f30b2078fbd3a2c3420":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"021daa632d4f4e4e9c53254150c8caa5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}